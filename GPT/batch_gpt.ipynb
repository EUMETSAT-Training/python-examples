{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GPT batch script"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This routine shows an example of how to use python to call SNAP's GPT processor, to allow automated processing of S3A OLCI L1 images from the command line.\n",
    "\n",
    "    Version: 1.0\n",
    "    Author: C Lebreton, Brockmann Consult\n",
    "    Notes:\n",
    "    1. A batch scripting version of the same file, batch_gpt.py, can be found in the same folder.\n",
    "    2. Both this script, and the batch version, will require you to adapt the paths to the GPT executable and data\n",
    "       on your local system.\n",
    "      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We begin by importing some python modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from os import path, listdir, system"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we have to tell our code where the GPT executable is. The default path is hown below, but you may have to adapt this depending on where you installed SNAP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONFIG\n",
    "# set up the environment, path to your gpt processor\n",
    "gptProcessor = '/usr/local/snap6/bin/gpt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we must point the code to our config file (in the same directory as this file), and the data we downloaded. It is the configuration file that describes the processes that SNAP will perform in our automated chain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define your graph xml, and input and output directory paths\n",
    "c2rcc_xml = path.join(os.getcwd(),'olci_c2rcc.xml')\n",
    "input_dir = path.join(os.getcwd(),'L1_subset')\n",
    "output_dir = path.join(os.getcwd(),'L2_batch')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we search the input directory to find Level-1 Sentinel-3 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INPUTS\n",
    "# make a list of all the input files in your input directory, only taking the .dim files\n",
    "input_files = [f for f in sorted(listdir(input_dir)) if\n",
    "               path.isfile(path.join(input_dir, f)) and path.basename(f).endswith('.dim')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And finally, we start the main part of our code, where we call GPT to process this L1 data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/shared/GPT/L1_subset/S3A_OL_1_EFR____20170527T100953_20170527T101253_20170528T142840_0179_018_122_1980_LN1_O_NT_002_subset.dim\n",
      "/shared/GPT/L2_batch/S3A_OL_1_EFR____20170527T100953_20170527T101253_20170528T142840_0179_018_122_1980_LN1_O_NT_002_subset_C2RCC.nc\n",
      "/usr/local/snap6/bin/gpt /shared/GPT/olci_c2rcc.xml -SsourceProduct=/shared/GPT/L1_subset/S3A_OL_1_EFR____20170527T100953_20170527T101253_20170528T142840_0179_018_122_1980_LN1_O_NT_002_subset.dim -t /shared/GPT/L2_batch/S3A_OL_1_EFR____20170527T100953_20170527T101253_20170528T142840_0179_018_122_1980_LN1_O_NT_002_subset_C2RCC.nc\n",
      "/shared/GPT/L1_subset/S3A_OL_1_EFR____20170528T094342_20170528T094642_20170528T114414_0179_018_136_1979_SVL_O_NR_002_subset.dim\n",
      "/shared/GPT/L2_batch/S3A_OL_1_EFR____20170528T094342_20170528T094642_20170528T114414_0179_018_136_1979_SVL_O_NR_002_subset_C2RCC.nc\n",
      "/usr/local/snap6/bin/gpt /shared/GPT/olci_c2rcc.xml -SsourceProduct=/shared/GPT/L1_subset/S3A_OL_1_EFR____20170528T094342_20170528T094642_20170528T114414_0179_018_136_1979_SVL_O_NR_002_subset.dim -t /shared/GPT/L2_batch/S3A_OL_1_EFR____20170528T094342_20170528T094642_20170528T114414_0179_018_136_1979_SVL_O_NR_002_subset_C2RCC.nc\n",
      "/shared/GPT/L1_subset/S3A_OL_1_EFR____20170601T093957_20170601T094257_20170602T140245_0179_018_193_1980_LN1_O_NT_002_subset.dim\n",
      "/shared/GPT/L2_batch/S3A_OL_1_EFR____20170601T093957_20170601T094257_20170602T140245_0179_018_193_1980_LN1_O_NT_002_subset_C2RCC.nc\n",
      "/usr/local/snap6/bin/gpt /shared/GPT/olci_c2rcc.xml -SsourceProduct=/shared/GPT/L1_subset/S3A_OL_1_EFR____20170601T093957_20170601T094257_20170602T140245_0179_018_193_1980_LN1_O_NT_002_subset.dim -t /shared/GPT/L2_batch/S3A_OL_1_EFR____20170601T093957_20170601T094257_20170602T140245_0179_018_193_1980_LN1_O_NT_002_subset_C2RCC.nc\n"
     ]
    }
   ],
   "source": [
    "# MAIN\n",
    "# this is the loop where the magic happens :-)\n",
    "# the loop goes over each input file in the input_files list\n",
    "for input_file in input_files:\n",
    "    # for gpt, you need the full path to the file (or you need to set your working environment)\n",
    "    input = path.join(input_dir, input_file)\n",
    "    print(input)\n",
    "    # the output file is named from the input file with the _C2RCCC suffix.\n",
    "    # Here you will write a netcdf file. this can be changed\n",
    "    output_product = path.join(output_dir, path.splitext(input_file)[0] + '_C2RCC.nc')\n",
    "    print(output_product)\n",
    "    # the processing call is a follows below. Make sure that you have the necessary spaces in between the calls\n",
    "    c2rcc_processingCall = gptProcessor + ' ' + c2rcc_xml + ' -SsourceProduct=' + input + ' -t ' + output_product\n",
    "    # useful to check that the command call is correct before launching the call (comment / uncomment the next line)\n",
    "    print(c2rcc_processingCall)\n",
    "    # python call, uncomment when the printed call satisfies your requirements\n",
    "    system(c2rcc_processingCall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
